#!/bin/bash
#PBS -q omp
#PBS -l select=1:ncpus=4:mem=60gb
#PBS -l walltime=10:00:00
#PBS -m e

# requires:
# - auto-kerchunk
# - dask-hpcconfig

cd $TMPDIR
source "/appli/anaconda/versions/4.8.2/etc/profile.d/conda.sh"
conda activate /home/datawork-lops-iaocea/conda-env/auto-kerchunk
#conda activate auto-kerchunk

FILES="file:///home/ref-marc/f1_e2500/best_estimate/*/*Z.nc"  
FILES="file:///home/datawork-cersat-public/provider/cci_sst/satellite/l3/AVHRRMTA_G/2006/*/*.nc" 
NAME="tinatest_cersat-public_provider_cci_sst_satellite_l3_AVHRRMTA_G"

TMP=$TMPDIR/JSONS
TMP=$DATAWORK/tmp/JSONS

CATALOGNAME=$NAME

RESULT="/home/datawork-lops-iaocea/catalog/kerchunk/$NAME.json.zst"
INTAKE="file:///home/datawork-lops-iaocea/catalog/intake/$NAME.yaml"
INTAKE="/home/datawork-lops-iaocea/catalog/intake/$NAME.yaml"

# create cluster and wait for the scheduler to have started
rm -rf scheduler_address
python -m dask_hpcconfig create datarmor --workers 28 --pidfile scheduler_address --silent &
until [ -f scheduler_address ]; do sleep 1; done

date
python -m auto_kerchunk single-hdf5-to-zarr \
       --cluster $(cat scheduler_address) \
       $FILES \
       $TMP
python -m auto_kerchunk multi-zarr-to-zarr \
       --cluster $(cat scheduler_address) \
       --compression zstd \
       "file://$TMP/*.json" \
       $RESULT
chmod go+w $RESULT
python -m auto_kerchunk   create-intake \
       --catalog-name $CATALOGNAME \
       --name  $NAME \
       "file://$RESULT" \
       "file://$INTAKE"
chmod go+w $INTAKE
date

# shut down the cluster
python -m dask_hpcconfig shutdown $(cat scheduler_address) --silent
